{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Exploration and Pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing \n",
    "import seaborn as sns\n",
    "import xgboost as xgb # type: ignore\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import joblib\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchantDetails = pd.DataFrame({\n",
    "\n",
    "})\n",
    "\n",
    "loanScheduleDetails = pd.DataFrame({\n",
    " \n",
    "})\n",
    "\n",
    "loanLedgerDetails = pd.DataFrame({\n",
    " \n",
    "})\n",
    "\n",
    "transactionDetails = pd.DataFrame({\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with same name\n",
    "\n",
    "merchantDetails.rename(columns={'id': 'merchant_code', 'created_at': 'merchant_created_at', 'updated_at':'merchant_updated_at'}, inplace=True)\n",
    "\n",
    "loanScheduleDetails.rename(columns={'id': 'loan_schedule_id', 'created_at': 'loan_schedule_created_at', 'updated_at':'loan_schedule_updated_at', 'paid_date':'loan_schedule_paid_date'}, inplace=True)\n",
    "\n",
    "loanLedgerDetails.rename(columns={'id': 'loan_id', 'created_at': 'loan_created_at', 'updated_at':'loan_updated_at', 'deleted_at':'loan_deleted_at', 'transaction_date':'loan_transaction_date', 'transaction_type':'loan_transaction_type', 'description':'loan_description'}, inplace=True)\n",
    "\n",
    "transactionDetails.rename(columns={'id': 'transaction_id', 'created_at': 'transaction_created_at'}, inplace=True)\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "\n",
    "merchantDetails[['merchant_created_at', 'merchant_updated_at']] = merchantDetails.apply(pd.to_datetime)\n",
    "\n",
    "loanScheduleDetails[['loan_schedule_created_at', 'loan_schedule_updated_at', 'loan_schedule_paid_date', 'schedule_date']] = loanScheduleDetails.apply(pd.to_datetime)\n",
    "\n",
    "loanLedgerDetails[['loan_created_at', 'loan_updated_at', 'loan_deleted_at']] = merchantDetails.apply(pd.to_datetime)\n",
    "\n",
    "transactionDetails[['transaction_datetime', 'transaction_created_at']] = transactionDetails.apply(pd.to_datetime)\n",
    "\n",
    "# Use loans only older than 3 months\n",
    "\n",
    "# Calculate the cutoff date for loans older than 3 months\n",
    "cutoff_date = pd.Timestamp.today() - pd.DateOffset(months=3)\n",
    "\n",
    "loanSchedule = loanScheduleDetails[loanScheduleDetails['schedule_date'] < cutoff_date]\n",
    "\n",
    "loanLedger = loanLedgerDetails[loanLedgerDetails['loan_created_at'] < cutoff_date]\n",
    "\n",
    "# Merge the data on 'merchant_code' to get only merchants who have or have had loans\n",
    "\n",
    "merchants = pd.merge(merchantDetails, loanSchedule[['merchant_code']], on='merchant_code', how='inner')\n",
    "\n",
    "# Filter transactionDetails to only include merchants who have taken loans and transactions prior to loan disbursement\n",
    "\n",
    "transactions = pd.merge(transactionDetails, loanSchedule[['merchant_code', 'loan_schedule_created_at']], on='merchant_code', how='inner')\n",
    "\n",
    "transactions = transactions[transactions['transaction_created_at'] < transactions['loan_schedule_created_at']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns and data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants.head()\n",
    "loanSchedule.head()\n",
    "loanLedger.head()\n",
    "transactions.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants.info()\n",
    "loanSchedule.info()\n",
    "loanLedger.info()\n",
    "transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping non-required columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants=merchants.drop([''],axis=1)\n",
    "loanSchedule=loanSchedule.drop([''],axis=1)\n",
    "loanLedger=loanSchedule.drop([''],axis=1)\n",
    "transactions=transactions.drop([''],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking and handling missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_info_merchants = merchants.isnull().sum()\n",
    "missing_info_loanSchedule = loanSchedule.isnull().sum()\n",
    "missing_info_loanLedger = loanLedger.isnull().sum()\n",
    "missing_info_transactions = transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['merchant_code'] = merchants['merchant_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merchant Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter loan ledger where transaction type is 'DISBURSEMENT'\n",
    "\n",
    "disbursement_df = loanLedger[loanLedger['loan_transaction_type'] == 'DISBURSEMENT']\n",
    "\n",
    "# Create a mapping from merchants to map merchant_created_at by merchant_code\n",
    "\n",
    "merchant_creation_map = merchants.set_index('merchant_code')['merchant_created_at'].to_dict()\n",
    "\n",
    "# Map merchant_created_at to disbursement_df based on merchant_code\n",
    "\n",
    "disbursement_df['merchant_created_at'] = disbursement_df['merchant_code'].map(merchant_creation_map)\n",
    "\n",
    "# Calculate the difference in days between merchant_created_at and transaction_date\n",
    "\n",
    "disbursement_df['relationage'] = (disbursement_df['loan_transaction_date'] - disbursement_df['merchant_created_at']).dt.days\n",
    "\n",
    "# Select only relevant columns: 'merchant_code' and 'age_at_disbursement'\n",
    "disbursement_age_df = disbursement_df[['merchant_code', 'relationage']]\n",
    "\n",
    "# Merge 'age_at_disbursement' into the existing DataFrame\n",
    "df = pd.merge(df, disbursement_age_df, on='merchant_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loan Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'merchant_code' and count unique 'pan' (customers)\n",
    "\n",
    "unique_customers_df = transactions.groupby('merchant_code')['pan'].nunique().reset_index()\n",
    "\n",
    "unique_customers_df.rename(columns={'pan': 'unique_customers'}, inplace=True)\n",
    "\n",
    "df = pd.merge(df, unique_customers_df, on='merchant_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trans_char(transactions, sales_period_end=1, sales_period_start=28, suffix=''):\n",
    "\n",
    "    # Merge disbursement date to transactions\n",
    "    disbursement_dates_amounts = loanLedger[loanLedger['loan_transaction_type'] == 'DISBURSEMENT']\n",
    "\n",
    "    transactions = pd.merge(transactions, disbursement_dates_amounts[['merchant_code', 'loan_transaction_date', 'debit']], on='merchant_code', how='left')\n",
    "    results = []\n",
    "\n",
    "    # Loop for each merchant\n",
    "    for merchant_code in transactions['merchant_code'].unique():\n",
    "\n",
    "        # Filter transactions for the specific merchant\n",
    "        merchant_transactions = transactions[transactions['merchant_code'] == merchant_code]\n",
    "        disbursement_date = merchant_transactions['loan_transaction_date'].iloc[0]\n",
    "\n",
    "        # Filter transactions for the sales period before disbursement\n",
    "        sales_period_transactions_all = merchant_transactions[\n",
    "            (merchant_transactions['transaction_datetime'] >= (disbursement_date - pd.Timedelta(days=sales_period_start))) &\n",
    "            (merchant_transactions['transaction_datetime'] <= (disbursement_date - pd.Timedelta(days=sales_period_end)))\n",
    "        ]\n",
    "\n",
    "        # Filter transactions by response_code = 0\n",
    "        sales_period_transactions = sales_period_transactions_all[sales_period_transactions_all['response_code'] == 0]\n",
    "\n",
    "       # Aggregate sales by date\n",
    "        daily_sales = sales_period_transactions.groupby(sales_period_transactions['transaction_datetime'].dt.date)['amount'].sum().reset_index(name='daily_sales')\n",
    "        daily_sales['transaction_datetime'] = pd.to_datetime(daily_sales['transaction_datetime'])\n",
    "\n",
    "        # Ensure continuity of dates: fill in missing dates with 0 sales\n",
    "        all_dates = pd.date_range(start=disbursement_date - pd.Timedelta(days=sales_period_start), end=disbursement_date - pd.Timedelta(days=sales_period_end))\n",
    "        daily_sales_continuous = pd.DataFrame({'transaction_datetime': all_dates})\n",
    "        daily_sales_continuous = pd.merge(daily_sales_continuous, daily_sales, on='transaction_datetime', how='left').fillna(0)\n",
    "        \n",
    "        # Average of total daily transaction value (in log)\n",
    "        avg_daily_sales = daily_sales_continuous['amount'].mean()\n",
    "        log_avg_transday = np.log1p(avg_daily_sales)\n",
    "        \n",
    "        # Average transaction sizes (in log)\n",
    "        avg_transaction_size = sales_period_transactions['amount'].mean()\n",
    "        log_avgtrans = np.log1p(avg_transaction_size)\n",
    "        \n",
    "        # Coefficient of variation of transaction sizes\n",
    "        std_dev_transaction_size = sales_period_transactions['amount'].std()\n",
    "        cv_trans = std_dev_transaction_size / avg_transaction_size if avg_transaction_size != 0 else 0\n",
    "        \n",
    "        # Coefficient of variation of total daily transaction values\n",
    "        std_dev_daily_sales = daily_sales_continuous['amount'].std()\n",
    "        cv_transday = std_dev_daily_sales / avg_daily_sales if avg_daily_sales != 0 else 0\n",
    "        \n",
    "        # Herfindahl-Hirschmann index of customers total transaction value\n",
    "        customer_sales = sales_period_transactions.groupby('pan')['amount'].sum()\n",
    "        total_sales = customer_sales.sum()\n",
    "        customer_sales_proportion = customer_sales / total_sales\n",
    "        HH_cust_trans = (customer_sales_proportion ** 2).sum()\n",
    "        \n",
    "        # Average of periods without any transactions (# of inactive days/total number of transaction days)\n",
    "        transaction_dates = sales_period_transactions['transaction_datetime'].dt.date.unique()\n",
    "        inactive_days = len(set(all_dates.date) - set(transaction_dates))\n",
    "        total_transaction_days = len(transaction_dates)\n",
    "        avg_inactivity = inactive_days / total_transaction_days if total_transaction_days != 0 else 0\n",
    "        \n",
    "        # Days since the period of longest inactivity\n",
    "        all_dates_df = pd.DataFrame(all_dates, columns=['date'])\n",
    "        all_dates_df['had_transaction'] = all_dates_df['date'].isin(transaction_dates)\n",
    "        all_dates_df['inactive_period'] = (all_dates_df['had_transaction'] == False).astype(int).diff().ne(0).cumsum()\n",
    "        inactive_periods = all_dates_df[all_dates_df['had_transaction'] == False].groupby('inactive_period')['date'].agg(['min', 'max', 'size'])\n",
    "        longest_inactivity_period = inactive_periods.loc[inactive_periods['size'].idxmax()]\n",
    "        days_since_max_inactivity = (disbursement_date.date() - longest_inactivity_period['max'].date()).days\n",
    "        \n",
    "        # Days since last transaction\n",
    "        last_transaction_date = sales_period_transactions['transaction_datetime'].max().date()\n",
    "        days_since_lasttrans = (disbursement_date.date() - last_transaction_date).days\n",
    "        \n",
    "        # (Relative to disbursal) Day with the largest transactions value\n",
    "        largest_transaction_day = daily_sales.loc[daily_sales['daily_sales'].idxmax(), 'transaction_datetime']\n",
    "        max_trans_dt = (largest_transaction_day - disbursement_date.date()).days\n",
    "    \n",
    "        # (Relative to disbursal) Day with most number of transactions\n",
    "        daily_transaction_count = sales_period_transactions.groupby(sales_period_transactions['transaction_datetime'].dt.date).size().reset_index(name='transaction_count')\n",
    "        most_transactions_day = daily_transaction_count.loc[daily_transaction_count['transaction_count'].idxmax(), 'transaction_datetime']\n",
    "        max_transcount_dt = (most_transactions_day - disbursement_date.date()).days\n",
    "        \n",
    "        # Days since last transaction of most frequent customer at the time of disbursal.\n",
    "        most_frequent_customer = sales_period_transactions.groupby('pan').size().idxmax()\n",
    "        most_frequent_customer_transactions = sales_period_transactions[sales_period_transactions['pan'] == most_frequent_customer]\n",
    "        most_frequent_customer_last_transaction_date = most_frequent_customer_transactions['transaction_datetime'].max().date()\n",
    "        dayspast_freqcust = (disbursement_date.date() - most_frequent_customer_last_transaction_date).days\n",
    "        \n",
    "        # Days since last transaction of largest customer at the time of disbursal.\n",
    "        largest_customer = sales_period_transactions.groupby('pan')['amount'].sum().idxmax()\n",
    "        largest_customer_transactions = sales_period_transactions[sales_period_transactions['pan'] == largest_customer]\n",
    "        last_transaction_largest_customer = largest_customer_transactions['transaction_datetime'].max().date()\n",
    "        dayspast_largcust = (disbursement_date.date() - last_transaction_largest_customer).days\n",
    "        \n",
    "        # Number of distinct customers within period (in log).\n",
    "        custcount = sales_period_transactions['pan'].nunique()\n",
    "        log_custcount = np.log1p(custcount)\n",
    "        \n",
    "        # Share of total transaction value conducted on {DayOfWeek}\n",
    "        sales_period_transactions['day_of_week'] = sales_period_transactions['transaction_datetime'].dt.dayofweek\n",
    "        transaction_value_by_day = sales_period_transactions.groupby('day_of_week')['amount'].sum()\n",
    "        total_transaction_value = sales_period_transactions['amount'].sum()\n",
    "        share_by_day_of_week = transaction_value_by_day / total_transaction_value\n",
    "        day_of_week_share = share_by_day_of_week.to_dict()\n",
    "        \n",
    "        shr_Mon_trans = day_of_week_share[0]\n",
    "        shr_Tue_trans = day_of_week_share[1]\n",
    "        shr_Wed_trans = day_of_week_share[2]\n",
    "        shr_Thu_trans = day_of_week_share[3]\n",
    "        shr_Fri_trans = day_of_week_share[4]\n",
    "        shr_Sat_trans = day_of_week_share[5]\n",
    "        shr_Sun_trans = day_of_week_share[6]\n",
    "        \n",
    "        results.append({'merchant_code': merchant_code, f'log_avg_transday{suffix}':log_avg_transday, f'log_avgtrans{suffix}':log_avgtrans, \n",
    "                        f'cv_trans{suffix}':cv_trans, f'cv_transday{suffix}':cv_transday, f'HH_cust_trans{suffix}':HH_cust_trans, \n",
    "                        f'avg_inactivity{suffix}':avg_inactivity, f'days_since_max_inactivity{suffix}':days_since_max_inactivity, \n",
    "                        f'days_since_lasttrans{suffix}':days_since_lasttrans, f'max_trans_dt{suffix}':max_trans_dt, \n",
    "                        f'max_transcount_dt{suffix}':max_transcount_dt, f'dayspast_freqcust{suffix}':dayspast_freqcust, \n",
    "                        f'dayspast_largcust{suffix}':dayspast_largcust, f'log_custcount{suffix}':log_custcount, \n",
    "                        f'shr_Mon_trans{suffix}':shr_Mon_trans, f'shr_Tue_trans{suffix}':shr_Tue_trans, \n",
    "                        f'shr_Wed_trans{suffix}':shr_Wed_trans, f'shr_Thu_trans{suffix}':shr_Thu_trans, \n",
    "                        f'shr_Fri_trans{suffix}':shr_Fri_trans, f'shr_Sat_trans{suffix}':shr_Sat_trans,\n",
    "                        f'shr_Sun_trans{suffix}':shr_Sun_trans})\n",
    "\n",
    "    trans_char_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "    return trans_char_df\n",
    "\n",
    "# 91 day period (long term - lt)\n",
    "\n",
    "trans_char_df_lt = calculate_trans_char(transactions, sales_period_end=1, sales_period_start=91, suffix='_lt')\n",
    "\n",
    "# 91 - 64 (t_1) and 1 - 28 (t_2) periods to then calculate change over lt\n",
    "\n",
    "trans_char_df_t_1 = calculate_trans_char(transactions, sales_period_end=64, sales_period_start=91, suffix='_t_1')\n",
    "\n",
    "trans_char_df_t_2 = calculate_trans_char(transactions, sales_period_end=1, sales_period_start=28, suffix='_t_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
